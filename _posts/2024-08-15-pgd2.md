---
layout: post
mathjax: true
title: Projected Gradient Descent Method - Line Search + GPU = Fast
date: 2024-08-15
category:
  - Blog
tags:
  - Python
  - Code
  - Optimization
  - GPGPU
---

This post is a revisit to the last post, where we are using projected gradient decent to solve an optimal portfolio problem. Here, we will get even larger performance gains then we did in the [last post](https://dkenefake.github.io/blog/pgd). This will be done by first modifying how large of a step we are doing in our gradient decent, and also solving this on the GPU. This post assumes you have read the last post, or are very familiar with gradient decent or optimization.

One of the most important features of gradient decent type algorithms is the choice in the step size ($\alpha$), in that a step size too small leads to very slow convergence while a step size too large means that the iterations diverge away from a local minimum. With the obvious bounds for the step size being zero, and the less obvious opper bound being $\frac{2}{L}$, with $L$ being the lipshitz constant of the gradient of the objective. In the last post I glossed over this. This value was estimated in the last post via the power iteration algorithm, and we set $\alpha_k \approx \frac{1}{2L}$ but this is not the most effective stratagy given that we have a route to derive a much more effective step size rule. 

The most powerful step size selection rule is optimal 1D line search. While for many nonlinear optimization problems, this is a bad idea as actually fully solving this problem to optimality is not cheap. However, for this problem there is a rather simple solution, that will give the best possible step size and removes 1) the need to compute the Lipschitz constant and 2) gives better improvements on each iteration.

$
\begin{align}
\alpha_k = \min_{\alpha} f(x_k - \alpha \nabla f(x_k))
\end{align}
$

The route to compute this is rather simple, we simply substitute the problem data into the line search problem and see that it simply becomes minimizing a convex 1D quadratic function, which can be solved in $O(1)$ time. Finding this function from the problem data unfortunately is $\mathcal{O}(n^2)$, but this is asymptotically the same cost as the gradient calculation as it involves a matrix-vector product. After some manipulation the step rule becomes the following.

$
\begin{align}
\alpha_k = -\frac{||\nabla f(x_k)||^2_2}{\nabla f(x_k)^TQ\nabla f(x_k)}
\end{align}
$

Implementing this in code is fairly simple, as it is just elementary linear algebra opteration that numpy can do.

```python

    # compute mat-vec of gradient and store it
    Qx = Q@x
    
    # compute the objective
    dx = Qx + c
    
    # compute the optimal step size
    grad_norm = float(numpy.linalg.norm(dx,2))**2
    dxQdx = float(dx.T@Q@dx))    
    alpha = -grad_norm / dxQdx
```


If we go back and apply it to the same problems we looked at in the last post we see a dramatic reduction in time to solve. I upgraded my computer since the last post so I benchmarked all of the algorithms again, and now that I have more RAM I can test out a larger problem that wouldn't have fit in memory previously. We can see some interesting things here, 1) time complexity of the PGD algorithms seems to be $\mathcal{O}(n^2)$ for this problem, as when we double the size of the problem we see approximately a quadrupling in the time to solve 2) with the exact line search we are approximately 4 times faster then with the fixed line search. 


| Asset Count | Gurobi       | PGD        | PGD + 1D |
|-------------|--------------|------------|----------|
| 10          | 0.024        | 0.001      |  0.001   |
| 100         | 0.051        | 0.001      |  0.001   |
| 500         | 0.162        | 0.008      |  0.004   |
| 1000        | 0.531        | 0.011      |  0.004   |
| 5000        | 36.53        | 0.279      |  0.089   |
| 10000       | 307.94       | 0.998      |  0.268   |
| 20000       | -            | 3.660      |  0.972   |

This is exciting news, in that we are now over 1000 times faster then gurobi for the largest problem type I was willing to wait to watch it solve. However, I wonder if we can do better in that we can operate solve this on the GPU. The GPU on my laptop is a mobile 4070, so that will be the baseline of the GPU. Here, I will bee doing a rather simple transformation of the code that we have written so far that is more or less just writing ``cupy`` instead of ``numpy`` when doing linear algebra operations. The code for this can be seen in the appendix.


It did take approximately one second to transfer the largest problem to the GPU from host memory, so the main bottleneck is transferring the problem to the GPU. So if you are only solving a single problem on the GPU with the same problem data, then it likely doesn't make much sense, however as this is a portfolio problem with a risk as a parameter, one would usually solve this problem over and over again with different risk levels. If these are left on the GPU then there the overhead of passing the problem data doesn't have to be paid for each problem. If we look at just raw solve times (if we just assume the data is where it is supposed to be), this is another 10x improvement over the 1D line search on the CPU. The number in parenthesis is the time it took to load the matrix and then solve the problem, and without is just time to solve. If we look at the GPU iteration progress, it only has to do 9 iterations before it is within our tolerance bounds, and if we do some back of the napkin math we are only using 1% of the theoretical FLOPS of the GPU and ~10% of the memory bandwidth. So given that, there is likely another multiplicative speed up with memory ordering operations and using a more direct interface.


| Asset Count | Gurobi       | PGD        | PGD + 1D |  PGD + 1D + GPU  | 
|-------------|--------------|------------|----------|------------------|
| 10          | 0.024        | 0.001      |  0.001   |  0.019 (0.020)   |
| 100         | 0.051        | 0.001      |  0.001   |  0.010 (0.011)   |
| 500         | 0.162        | 0.008      |  0.004   |  0.013 (0.016)   |
| 1000        | 0.531        | 0.011      |  0.004   |  0.010 (0.11)    |
| 5000        | 36.53        | 0.279      |  0.089   |  0.024 (0.11)    |
| 10000       | 307.94       | 0.998      |  0.268   |  0.042 (0.32)    |
| 20000       | -            | 3.660      |  0.972   |  0.096 (1.28)    |

So starting from a place of beating a commercial solver, by two orders of magnitude to now moving into the three order domain (if we if we ignore data transfer overhead) by combining 1D line search with GPU compute!

# Code Listings

```python
x_gpu = cupy.asarray(x_0.copy(), dtype = cupy.float32)
objs = []

for i in range(100):
    
    # compute mat-vec of gradient and store it
    Qx = Q_gpu@x_gpu
    
    # compute the objective and store it
    objs.append(float(0.5*x_gpu.T@Qx +c_gpu.T@x_gpu))
    
    # compute the objective
    dx = Qx + c_gpu
    
    # compute the optimal step size
    grad_norm = float(cupy.linalg.norm(dx,2))**2
    dxQdx = float(dx.T@(Q_gpu@dx))    
    alpha = -grad_norm / dxQdx
    
    # make gradient decent move
    y = x_gpu + alpha*dx_
    
    # project back to simplex using the CPU based code - kinda ugly 
    x_gpu = cupy.asarray(project_to_simplex(y.get().flatten())).reshape(-1,1)
    
    if i > 2:
        if objs[-2] - objs[-1] <= 10**-10:
            break
 ```
